<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Satisficing strategies</title>

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/solarized.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <style type="text/css">
      .source {
        font-size: 60%;
      }
     .example table td + td{
         border-left: 1px #586e75 solid;
     }
    </style>

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>
  </head>
  <body>
    <div class="reveal">
      <div class="slides">

       <!-- Kelvin part: -->
        <section data-markdown>
          <script type="text/template">
			# Satisficing strategies
			---
			Kelvin Lubbertsen, Jappie Klooster
          </script>
        </section>
        <section data-markdown>
			## Normal situation
			- Optimizing agents
			- Examples
				- Dominant strategies
				- No-regret
        </section>					
		<section data-markdown>
			<script type="text/template">
			## Satisficing
			- More natural: satisficing
			- Introduced by Herbert Simon
			- "good enough"
			
			![](img/simon.png) 
			</script>
		</section>
		
		<section data-markdown>
			## Satisficing in game theory
			- Algorithm by Karandikar (1998)
			- Prisoner's dilemma analyzed by Stimpson et al. (2001)
			- Multi agent social dilemma by Stimpson & Goodrich (2003)
		</section>
		
		<section data-markdown>
			## Why?
			- People are not always playing rational
			- Shown for instance by John Conlisk (1996)
			- Normally focused on learning Nash equilibrium
		</section>
		
		<section data-markdown>
			## Why?
			- Drawbacks of learning Nash equilibrium:
				- By Axelrod (1984): in repeated play not only stable solution with desired properties
				- Requires significant assumptions
		</section>
        <section data-markdown>
			## Assumptions
			- Such assumptions are:
				- Structure of game known to players
				- Players aware of other player's decisions & payoffs
				- Players aware that they are in a game situation
			- Often at least one assumption involved
        </section>
		<section data-markdown>
			## Assumptions
			- Limiting
			- Sometimes structure of game even not known by decision maker
		</section>
        <section data-markdown>
			## When?
			- Social dilemma
			- Uncertain situations
        </section>
        <section>
        <section>
            <h1>Algorithm</h1>
            <!-- mention symon-->
            <ol>
                <li>
            $ \begin{cases}
            \text{if } \pi_t \geq \alpha_t & A_{t+1} = A_t\\
            \text{else} & A_{t+1} \neq A_t
            \end{cases}$
                </li>
                <li>
                    $ \alpha_{t+1} = \lambda \alpha_t + (1-\lambda) \pi_t $
                    <br/>
                    <small>Where $0 \leq \lambda \leq 1$</small>
                </li>
            </ol>
            <table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
            <colgroup>
            <col  class="org-left" />
            <col  class="org-left" />
            </colgroup>
            <tbody>
                <tr>
                    <td class="org-left">Time</td>
                    <td class="org-left">$t$</td>
                </tr>
                <tr>
                    <td class="org-left">Action in $\{C,D\}$</td>
                    <td class="org-left">$A_t$</td>
                </tr>
                <tr>
                    <td class="org-left">Aspiration level</td>
                    <td class="org-left">$\alpha_t$</td>
                </tr>
                <tr>
                    <td class="org-left">Utility</td>
                    <td class="org-left">$\pi_t$</td>
                </tr>
            </tbody>
            </table>
        </section>
        <section data-markdown class="example">
        <script type="text/template">
        # VS always cooporate

        t | Coop | $A_t$ | $\pi_t$ | $\alpha_t$
        --- | --- | ---- | ------- | ---   
        0 | C     | C    | 3       | 4 
        1 | C     | D    | 4       | 3.5
        2 | C     | D    | 4       | 3.75
        3 | C     | D    | 4       | 3.875

        $$ \vdots $$

        </script>
        </section>
        <section data-markdown class="example">
        <script type="text/template">
        # VS always cooporate II

        t | Coop | $A_t$ | $\pi_t$ | $\alpha_t$
        --- | --- | ---- | ------- | ---   
        0 | C     | C    | 3       | 2
        1 | C     | C    | 3       | 2.5
        2 | C     | C    | 3       | 2.75
        3 | C     | C    | 3       | 2.875

        $$ \vdots $$

        </script>
        </section>
        <section data-markdown class="example">
        <script type="text/template">
        # VS Tit for Tat

        t | TT | $A_t$ | $\pi_t$ | $\alpha_t$
        --- | --- | ---- | ------- | ---   
        0 | C     | C    | 3       | 4 
        1 | C     | D    | 4       | 3.5
        2 | D     | D    | 2       | 3.75
        3 | D     | C    | 1       | 2.87
        4 | C     | D    | 4       | 3.435
        5 | D     | D    | 2       | 2.715
        6 | D     | C    | 1       | 1.85875

        $$ \vdots $$

        </script>
        </section>
        </section>

        <section data-markdown>
        # Experimental results
        * Always satisficing vs satisficing.
        * Over many trials.
        * Variables were set randomly.
        * All graphs work with percentage of total.
        </section>

        <section data-markdown>
        # Possible outcomes
        1. Convergence to certain actions (Cooperate)
        2. Action cycle (TT)
        3. Complete chaos ??
        </section>

        <section data-markdown>
        <script type="text/template">
        # Outcomes
        ![](img/strategies.png) <!-- .element: width="450px" -->

        Over 5000 trials.
        </script>
        </section>
        <section data-markdown>
        <script type="text/template">
        # Aspiration
        ![](img/aspiration.png)<!-- .element: width="650px" -->

        Over 1000 trials.
        </script>
        </section>
        <section>
            <h1> Generalized dillemma </h1>
            <table>
                <tr>
                    <th> </th><th> Cooperate </th><th> Defect </th>
                </tr>
                <tr>
                    <th> Cooperate </th> <td> $(\sigma, \sigma)$ </td> <td> 0,1</td>
                </tr>
                <tr>
                    <th> Defect </th>  <td> 1,0</td> <td> $(\delta, \delta)$ </td>
                </tr>
            </table>
           <p>
               Where $(0<\delta < \sigma < 1)$ and $\sigma > 0.5$.
           </p>
        </section>
        <section data-markdown>
        # Contrast
        ![](img/contrast.png)

        * Over 1000 trials.
        * *As long as it is not diffiuclt to discriminate*

        </section>
        <section data-markdown>
        <script type="text/template">
        # Learning rate
        ![](img/learning-rate.png)<!-- .element: width="800px" -->
        </script>
        </section>
		<section data-markdown>
			## Multi-agent social dilemma
			- Generalized form of prisoner's dilemma
			- Choose between: own goal vs. group goal
			- Satisficing strategies perform better then pure Nash equilibrium
        </section>
		
		<section data-markdown>
			## Multi-agent social dilemma
			- $N$ agents
			- Resource allocation:
				- $M$ units of discrete resource
				- Choose between self-interested goal $S_i$ and group goal $G$
			
		</section>
		
		<section data-markdown>
			## Multi-agent social dilemma
			- Weights for goals: $K_G = \frac{1}{NM}$ $K_S = \frac{k}{M}$
			- $k < 1$: more interested in own goal
			- $k > \frac{1}{N}$: more interested in group goal
			- Range: $1 > k > \frac{1}{N}$
		</section>
		
		<section data-markdown>
			## Social dilemma properties
			- Extreme individual rewards (self-interested)
			- Extreme average rewards (only group focused play)
			- Nash equilibrium: selfish play
			- Nash bargaining solution: only focused on group goal
		</section>

		<section>
			<section data-markdown>
				## Multi-agent social dilemma experiments
				- Experiments by Stimpson & Goodrich (2003)
					
				- Desired properties based on Bowling & Veloso (2000)
					- Reach Pareto efficient solution in self-play
					- Not exploited by selfish agents
			</section>
			<section data-markdown>
				## Belief based learning experiments
				- Belief based learning based on Feltovich (2000)
				- Set of weights over opponent's actions
				- Does not learn mutual cooperation
					- Theoretically shown
			</section>
			<section data-markdown>
				<script type="text/template">
				## Q-learning
				- Converges sometimes to Pareto optimal
				- $M$ = 1, meaning:
					- Agents have 2 choices: group goal or selfish goal
				</script>
			</section>
			<section data-markdown>
				<script type="text/template">
				## Q-learning
				![](img/q-learning.PNG)<!-- .element: width="600px" -->
				- Parameters of learning rate, discount factor and $k$ make no big difference
				</script>
			</section>
			<section data-markdown>
				## Q-learning
				- Tend to learn best response strategies
				- But: mutual cooperation difficult to learn
			</section>
			<section data-markdown>
				## Satisficing algorithm
				- Learning rate $\lambda$:
					- $\lambda * 100 \%$ of previous aspiration level forms basis for new aspiration level
				- 500 runs
			</section>
			<section data-markdown>
				<script type="text/template">
				## Satisficing algorithm
				![](img/satisficing-algorithm.png) <!-- .element: width="600px" -->
				</script>
			</section>
			<section data-markdown>
				## Satisficing algorithm
				- Converges to Nash equilibrium when playing against self-play
				- Converges to Nash bargaining equilibrium when playing against satisficing algorithm
			</section>
		</section>
        <section data-markdown>
        # [Demo](http://www.cs.uu.nl/docs/vakken/maa/current/netlogo_satisficing_play.php)
        </section>

        <section data-markdown>
        # Discussion
        - Win-stay lose-shift vs Satisficing strategies
        - Applications outside game theory
        </section>

      </div>
    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>

    <script>
      // More info https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        history: true,

        // More info https://github.com/hakimel/reveal.js#dependencies
        dependencies: [
          { src: 'plugin/markdown/marked.js' },
          { src: 'plugin/markdown/markdown.js' },
          { src: 'plugin/notes/notes.js', async: true },
          { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
            { src: 'plugin/math/math.js', async: true }
        ]
      });
     // Make each section with the example class the rows of the classes pop-in
     $(function(){
         match = $(".example tr").not(function(i,element){
             return $(element).children("th").size() !== 0;
         }).addClass("fragment")
     })
    </script>
  </body>
</html>
